{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haskari/miniconda3/envs/paraphrase/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import pickle as pkl\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bad_indice(name,model):\n",
    "    if model!='gpt3.5-T':\n",
    "        if name=='cnn':\n",
    "            with open('{}/data_paraphrase/cnn.pkl'.format(model), 'rb') as f:\n",
    "                paraphrased_summaries=pkl.load(f)\n",
    "        elif name=='xsum':\n",
    "            with open('{}/data_paraphrase/xsum_capped_random.pkl'.format(model), 'rb') as f:\n",
    "                paraphrased_summaries=pkl.load(f)\n",
    "            \n",
    "        elif name=='news':\n",
    "            with open('{}/data_paraphrase/news_capped_random.pkl'.format(model), 'rb') as f:\n",
    "                paraphrased_summaries=pkl.load(f)\n",
    "        \n",
    "        else:\n",
    "            with open('{}/data_paraphrase/reddit_capped_random.pkl'.format(model), 'rb') as f:\n",
    "                paraphrased_summaries=pkl.load(f)\n",
    "    else:\n",
    "        print('here')\n",
    "        if name=='cnn':\n",
    "            with open('{}/data_paraphrase/cnn.pkl'.format(model), 'rb') as f:\n",
    "                paraphrased_summaries=pkl.load(f)\n",
    "        elif name=='xsum':\n",
    "            with open('{}/data_paraphrase/xsum.pkl'.format(model), 'rb') as f:\n",
    "                paraphrased_summaries=pkl.load(f)\n",
    "            \n",
    "        elif name=='news':\n",
    "            with open('{}/data_paraphrase/news.pkl'.format(model), 'rb') as f:\n",
    "                paraphrased_summaries=pkl.load(f)\n",
    "        \n",
    "        else:\n",
    "            with open('{}/data_paraphrase/reddit.pkl'.format(model), 'rb') as f:\n",
    "                paraphrased_summaries=pkl.load(f)\n",
    "        \n",
    "    bad_index=[]\n",
    "    for idx,sum in enumerate(paraphrased_summaries):\n",
    "        if sum == []:\n",
    "            bad_index.append(idx)\n",
    "    return bad_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'indices'=<generator object <genexpr> at 0x7fc8c2506ce0> of the transform datasets.arrow_dataset.Dataset.select couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    }
   ],
   "source": [
    "#paraphrased mistral-7b\n",
    "\n",
    "p_data_mistral_cnn = datasets.load_from_disk(\"llama2/saved_models/paraphrase-LlaMa2-cnn/\")\n",
    "\n",
    "p_data_mistral_xsum = datasets.load_from_disk(\"llama2/saved_models/paraphrase-LlaMa2-xsum/\")\n",
    "\n",
    "p_data_mistral_news = datasets.load_from_disk(\"llama2/saved_models/paraphrase-LlaMa2-news/\")\n",
    "\n",
    "p_data_mistral_reddit = datasets.load_from_disk(\"llama2/saved_models/paraphrase-LlaMa2-reddit/\")\n",
    "\n",
    "\n",
    "#original mistral-7b\n",
    "\n",
    "data_mistral_cnn = datasets.load_from_disk(\"llama2/saved_models/original-LlaMa2-cnn/\")\n",
    "\n",
    "bad_index=get_bad_indice('cnn','llama2')\n",
    "data_mistral_cnn=data_mistral_cnn.select(i for i in range(len(data_mistral_cnn)) \n",
    "                 if i not in set(bad_index))\n",
    "\n",
    "\n",
    "data_mistral_xsum = datasets.load_from_disk(\"llama2/saved_models/original-LlaMa2-xsum/\")\n",
    "\n",
    "bad_index=get_bad_indice('xsum','llama2')\n",
    "data_mistral_xsum=data_mistral_xsum.select(i for i in range(len(data_mistral_xsum)) \n",
    "                 if i not in set(bad_index))\n",
    "\n",
    "data_mistral_news = datasets.load_from_disk(\"llama2/saved_models/original-LlaMa2-news/\")\n",
    "\n",
    "bad_index=get_bad_indice('news','llama2')\n",
    "data_mistral_news=data_mistral_news.select(i for i in range(len(data_mistral_news)) \n",
    "                 if i not in set(bad_index))\n",
    "\n",
    "\n",
    "data_mistral_reddit = datasets.load_from_disk(\"llama2/saved_models/original-LlaMa2-reddit/\")\n",
    "\n",
    "bad_index=get_bad_indice('reddit','llama2')\n",
    "data_mistral_reddit=data_mistral_reddit.select(i for i in range(len(data_mistral_reddit)) \n",
    "                 if i not in set(bad_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ups', 'num_comments', 'upvote_ratio', 'score', 'documents', 'tldr', 'title', 'original_article', 'article', 'highlights', 'segment_idxs', 'mapping', 'article_length', 'highlights_length', 'model_summaries', 'mapping_gen'],\n",
       "    num_rows: 323\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data_mistral_reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ups', 'num_comments', 'upvote_ratio', 'score', 'documents', 'tldr', 'title', 'original_article', 'article', 'highlights', 'segment_idxs', 'mapping', 'article_length', 'highlights_length', 'model_summaries', 'mapping_gen'],\n",
       "    num_rows: 339\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mistral_reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wore a hot dog costume to school and while i ran during cross country practice and got called wiener by everyone for the years to come.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data_mistral_reddit['highlights'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The author was nicknamed \"Wiener\" in middle school due to wearing a hot dog costume on Halloween and being teased by students and a teacher, who found it hilarious but the author now realizes was kind of fucked up']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data_mistral_reddit['model_summaries'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing metric scores....\n",
      "computing nli scores (direction avg + formula e)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "averaging....\n",
      "combing scores...\n",
      "computing metric scores....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haskari/miniconda3/envs/paraphrase/lib/python3.12/site-packages/bert_score/scorer.py:178: UserWarning: Overwriting the previous importance weights.\n",
      "  warnings.warn(\"Overwriting the previous importance weights.\")\n",
      "3it [00:02,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing nli scores (direction avg + formula e)...\n",
      "averaging....\n",
      "combing scores...\n",
      "computing metric scores....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:03,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing nli scores (direction avg + formula e)...\n",
      "averaging....\n",
      "combing scores...\n",
      "computing metric scores....\n",
      "computing nli scores (direction avg + formula e)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:04,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "averaging....\n",
      "combing scores...\n",
      "computing metric scores....\n",
      "computing nli scores (direction avg + formula e)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:05,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "averaging....\n",
      "combing scores...\n",
      "computing metric scores....\n",
      "computing nli scores (direction avg + formula e)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:06,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "averaging....\n",
      "combing scores...\n",
      "computing metric scores....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:07,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing nli scores (direction avg + formula e)...\n",
      "averaging....\n",
      "combing scores...\n",
      "computing metric scores....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:08,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing nli scores (direction avg + formula e)...\n",
      "averaging....\n",
      "combing scores...\n",
      "computing metric scores....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:09,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing nli scores (direction avg + formula e)...\n",
      "averaging....\n",
      "combing scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:09,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "#from MENLI import MENLI\n",
    "from MENLI.MENLI import MENLI\n",
    "\n",
    "scorer = MENLI(direction=\"avg\", formula=\"e\", src=False, nli_weight=0.3, combine_with=\"BERTScore-F\", model=\"D\")\n",
    "res=[]\n",
    "count=0\n",
    "# refs and hyps in form of list of String\n",
    "for cand, ref in tqdm(zip(p_data_mistral_cnn['highlights'],p_data_mistral_cnn['model_summaries'])):\n",
    "    count+=1\n",
    "    # if count>=20:\n",
    "    #     break\n",
    "    if len(cand)!=len(ref):\n",
    "        continue\n",
    "    if not cand or not ref:\n",
    "        continue\n",
    "    scores=scorer.score_all(srcs=[],refs=cand, hyps=ref) \n",
    "\n",
    "    res.append(sum(scores)/len(scores))\n",
    "    \n",
    "   \n",
    "return sum(res)/len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4038774366533841,\n",
       " 0.40349568840067307,\n",
       " 0.4383746677079836,\n",
       " 0.3615079469181343,\n",
       " 0.42108726991601736,\n",
       " 0.5130963350462044,\n",
       " 0.41315686720297434,\n",
       " 0.46100161126459893,\n",
       " 0.4171322914520195]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4258589016179989"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(res)/len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paraphrase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
