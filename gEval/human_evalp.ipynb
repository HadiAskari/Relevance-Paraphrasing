{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "from natsort import natsorted\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haskari/miniconda3/envs/paraphrase/lib/python3.12/site-packages/datasets/load.py:1461: FutureWarning: The repository for xsum contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/xsum\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cnn_ds = datasets.load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "cnn_ds = cnn_ds['test']\n",
    "\n",
    "xsum_ds = datasets.load_dataset(\"xsum\")    \n",
    "xsum_ds = xsum_ds['test']\n",
    "\n",
    "news_ds = datasets.load_dataset(\"argilla/news-summary\")\n",
    "news_ds = news_ds['train']\n",
    "\n",
    "reddit_ds = datasets.load_dataset(\"reddit_tifu\", \"long\")\n",
    "train_testvalid = reddit_ds['train'].train_test_split(test_size=0.2, seed=42)\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, seed=42)\n",
    "reddit_ds = test_valid['test']\n",
    "\n",
    "\n",
    "# Article and summary keys\n",
    "ds_keys = {'cnn_ds':['article', 'highlights'],\\\n",
    "            'xsum_ds':['document', 'summary'], \\\n",
    "            'news_ds':['text', 'prediction'], \\\n",
    "            'reddit_ds':['documents', 'tldr']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_paraphrased_summaries(path):\n",
    "    \"\"\"Reads all .pkl files within a directory into strings.\n",
    "\n",
    "    Args:\n",
    "        path (str): The path to the directory containing .pkl files.\n",
    "\n",
    "    Yields:\n",
    "        tuple: A tuple containing (filename, file_content_string) for each .pkl file.\n",
    "    \"\"\"\n",
    "\n",
    "    out = []\n",
    "    files = natsorted(os.listdir(path))\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".pkl\"):\n",
    "            filepath = os.path.join(path, filename)\n",
    "            with open(filepath, 'rb') as f:\n",
    "                file_content = pickle.load(f)\n",
    "                out.append(file_content[0])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_summaries(path):\n",
    "    out = []\n",
    "    with open(path, 'rb') as f:\n",
    "        content = pickle.load(f)\n",
    "        for ls in content:\n",
    "            out.append('\\n'.join(ls))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "origSummaryPath = '../mistral-7b/data_original/'\n",
    "#cnn_sum_orig = read_summaries(origSummaryPath+'cnn.pkl')\n",
    "xsum_sum_orig = read_summaries(origSummaryPath+'xsum_capped_random.pkl')\n",
    "#news_sum_orig = read_summaries(origSummaryPath+'news_capped_random.pkl')\n",
    "reddit_sum_orig = read_summaries(origSummaryPath+'reddit_capped_random.pkl')\n",
    "\n",
    "\n",
    "paraSummaryPath = '../mistral-7b/data_paraphrase/'\n",
    "#cnn_sum_para = read_summaries(paraSummaryPath+'cnn.pkl')\n",
    "xsum_sum_para = read_summaries(paraSummaryPath+'xsum_capped_random.pkl')\n",
    "#news_sum_para = read_summaries(paraSummaryPath+'news_capped_random.pkl')\n",
    "reddit_sum_para = read_summaries(paraSummaryPath+'reddit_capped_random.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_indices=[0,3,6,7,8,9,11,13,14,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my girlfriend was over at my house and was on my computer so i decided to have some fun by using  an app that allows you to control your computer using your smartphone.. so i closed the page she was on a couple of times  and she freaked out and i just said it must have been her doing it.\\n\\nafter that i just really subtly moved the mouse and she would scream at me that it moved and was getting hysterical (yes i should have stopped long before now). every time i just said she must have moved it or she was just imagining the mouse move.\\n\\nthis went on for hours but i decided to escalate it (i am a fucking idiot) by openining up chrome while she wasn’t looking and typing “hi”. she kept going on about how i have a virus and i need to do something and i just couldn’t help but laugh even though i could see she was panicking.\\n\\nso then my finale, i opened up power point and typed “webcam ?”, this time she got really worried and was absolutely freaking the fuck out and i was still laughing my ass off like a bell-end. bear in mind she had been watching the screen like a hawk for a few hours now. she typed back “no” and then i left it for about 20 minutes before i slowly moved the cursor across the screen went through my programs and started opening the webcam application and at this point she leapt up and closed it and shut the laptop.\\n\\ni was fucking losing it and had to admit it was me the whole time, i have never seen her get so mad before. she said she could never trust me again and refused to talk to me.  she has just left and i wont be able to see her for a couple of weeks now… i gone goofed\\n\\n \\n\\n…no more blow jobs for a while i guess'"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_ds['documents'][22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'; crossed paths with someone in the universe whose stardust created a strong chemical reaction with mine and i didn’t even get a name.'"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_ds['tldr'][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm going on a trip to Europe with my family\""
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sent_tokenize(xsum_sum_orig[9])[0]\n",
    "reddit_sum_orig[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_indices=[0,3,6,7,8,9,11,13,14,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Providing false information increases the value of the survey respondent's opinion\""
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sent_tokenize(xsum_sum_para[9])[0]\n",
    "reddit_sum_para[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
