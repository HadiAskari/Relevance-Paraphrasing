{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mz/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mz/.local/lib/python3.10/site-packages/datasets/load.py:1454: FutureWarning: The repository for xsum contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/xsum\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cnn_ds = datasets.load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "cnn_ds = cnn_ds['test']\n",
    "\n",
    "xsum_ds = datasets.load_dataset(\"xsum\")    \n",
    "xsum_ds = xsum_ds['test']\n",
    "\n",
    "news_ds = datasets.load_dataset(\"argilla/news-summary\")\n",
    "news_ds = news_ds['train']\n",
    "\n",
    "reddit_ds = datasets.load_dataset(\"reddit_tifu\", \"long\")\n",
    "train_testvalid = reddit_ds['train'].train_test_split(test_size=0.2, seed=42)\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, seed=42)\n",
    "reddit_ds = test_valid['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article': '(CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the court is based. The Palestinians signed the ICC\\'s founding Rome Statute in January, when they also accepted its jurisdiction over alleged crimes committed \"in the occupied Palestinian territory, including East Jerusalem, since June 13, 2014.\" Later that month, the ICC opened a preliminary examination into the situation in Palestinian territories, paving the way for possible war crimes investigations against Israelis. As members of the court, Palestinians may be subject to counter-charges as well. Israel and the United States, neither of which is an ICC member, opposed the Palestinians\\' efforts to join the body. But Palestinian Foreign Minister Riad al-Malki, speaking at Wednesday\\'s ceremony, said it was a move toward greater justice. \"As Palestine formally becomes a State Party to the Rome Statute today, the world is also a step closer to ending a long era of impunity and injustice,\" he said, according to an ICC news release. \"Indeed, today brings us closer to our shared goals of justice and peace.\" Judge Kuniko Ozaki, a vice president of the ICC, said acceding to the treaty was just the first step for the Palestinians. \"As the Rome Statute today enters into force for the State of Palestine, Palestine acquires all the rights as well as responsibilities that come with being a State Party to the Statute. These are substantive commitments, which cannot be taken lightly,\" she said. Rights group Human Rights Watch welcomed the development. \"Governments seeking to penalize Palestine for joining the ICC should immediately end their pressure, and countries that support universal acceptance of the court\\'s treaty should speak out to welcome its membership,\" said Balkees Jarrah, international justice counsel for the group. \"What\\'s objectionable is the attempts to undermine international justice, not Palestine\\'s decision to join a treaty to which over 100 countries around the world are members.\" In January, when the preliminary ICC examination was opened, Israeli Prime Minister Benjamin Netanyahu described it as an outrage, saying the court was overstepping its boundaries. The United States also said it \"strongly\" disagreed with the court\\'s decision. \"As we have said repeatedly, we do not believe that Palestine is a state and therefore we do not believe that it is eligible to join the ICC,\" the State Department said in a statement. It urged the warring sides to resolve their differences through direct negotiations. \"We will continue to oppose actions against Israel at the ICC as counterproductive to the cause of peace,\" it said. But the ICC begs to differ with the definition of a state for its purposes and refers to the territories as \"Palestine.\" While a preliminary examination is not a formal investigation, it allows the court to review evidence and determine whether to investigate suspects on both sides. Prosecutor Fatou Bensouda said her office would \"conduct its analysis in full independence and impartiality.\" The war between Israel and Hamas militants in Gaza last summer left more than 2,000 people dead. The inquiry will include alleged war crimes committed since June. The International Criminal Court was set up in 2002 to prosecute genocide, crimes against humanity and war crimes. CNN\\'s Vasco Cotovio, Kareem Khadder and Faith Karimi contributed to this report.',\n",
       " 'highlights': 'Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June .\\nIsrael and the United States opposed the move, which could open the door to war crimes investigations against Israelis .',\n",
       " 'id': 'f001ec5c4704938247d27a44948eebb37ae98d01'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "def read_pkl_files(path):\n",
    "    \"\"\"Reads all .pkl files within a directory into strings.\n",
    "\n",
    "    Args:\n",
    "        path (str): The path to the directory containing .pkl files.\n",
    "\n",
    "    Yields:\n",
    "        tuple: A tuple containing (filename, file_content_string) for each .pkl file.\n",
    "    \"\"\"\n",
    "\n",
    "    out = []\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".pkl\"):\n",
    "            filepath = os.path.join(path, filename)\n",
    "            with open(filepath, 'rb') as f:\n",
    "                file_content = pickle.load(f)\n",
    "                file_content_string = str(file_content)  # Convert to string representation \n",
    "                out.append(file_content_string)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../gpt3.5-T/data_paraphrase/'\n",
    "cnn_sum_para = read_pkl_files(path+'cnn/')\n",
    "xsum_sum_para = read_pkl_files(path+'xsum/')\n",
    "news_sum_para = read_pkl_files(path+'news/')\n",
    "reddit_sum_para = read_pkl_files(path+'reddit/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(cnn_sum_para): 11490\n",
      "    len(xsum_sum_para): 11334\n",
      "    len(news_sum_para): 1000\n",
      "    len(reddit_sum_para): 4214\n"
     ]
    }
   ],
   "source": [
    "_ = ic(len(cnn_sum_para), len(xsum_sum_para), len(news_sum_para), len(reddit_sum_para))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cnn_sum_para[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_orig_summaries(path):\n",
    "    out = []\n",
    "    with open(path, 'rb') as f:\n",
    "        content = pickle.load(f)\n",
    "        for ls in content:\n",
    "            out.append('\\n'.join(ls))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "origSummaryPath = '../gpt3.5-T/data_original/'\n",
    "cnn_sum_orig = read_orig_summaries(origSummaryPath+'cnn_new_new.pkl')\n",
    "xsum_sum_orig = read_orig_summaries(origSummaryPath+'xsum_new_new.pkl')\n",
    "news_sum_orig = read_orig_summaries(origSummaryPath+'news_new_new.pkl')\n",
    "reddit_sum_orig = read_orig_summaries(origSummaryPath+'reddit_new_new.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pilot of the doomed Germanwings flight in a Facebook comment.\\nBachmann claims that Obama is like Andreas Lubitz, a deranged pilot who flew his entire nation into the rocks with his Iran deal.\\nBachmann's comments were widely criticized and accused of being inappropriate and divisive.\""
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_sum_orig[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(cnn_sum_para) == len(cnn_sum_orig)\n",
    "assert len(xsum_sum_para) == len(xsum_sum_orig)\n",
    "assert len(news_sum_para) == len(news_sum_orig)\n",
    "assert len(reddit_sum_para) == len(reddit_sum_orig)\n",
    "\n",
    "\n",
    "assert len(cnn_sum_para) == len(cnn_ds)\n",
    "assert len(xsum_sum_para) == len(xsum_ds)\n",
    "assert len(news_sum_para) == len(news_ds)\n",
    "assert len(reddit_sum_para) == len(reddit_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_keys = {'cnn_ds':['article', 'highlights'],\\\n",
    "            'xsum_ds':['document', 'summary'], \\\n",
    "            'news_ds':['text', 'prediction'], \\\n",
    "            'reddit_ds':['document', 'tldr']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratePromptGood(article, summary):\n",
    "    prompt = \"\"\"\n",
    "\n",
    "    You will be given one summary written for a news article. Your task is to rate the summary based on the following criteria:\n",
    "    Output format: PERCENTAGE, PERCENTAGE, PERCENTAGE, PERCENTAGE, PERCENTAGE\n",
    "\n",
    "    Evaluation Criteria:\n",
    "    1. Read the news article carefully and identify the main topic and key points.\n",
    "    2. Read the summary and compare it to the news article. Check if the summary covers the main topic and key points of the news article, and if it resents them in a clear and logical order.\n",
    "    3. Rate the summary with 5 percentages, where each one represents how likely the summary is going to get a score from 1 to 5. For example, if you think the summary is 80% likely to get a score of 5, 10% likely to get a score of 4, 5% likely to get a score of 3, 3% likely to get a score of 2, and 1% likely to get a score of 1, you should rate the summary as 80, 10, 5, 3, 2.\n",
    "\n",
    "    Here is the article: {article}\n",
    "\n",
    "    Here is the summary: {summary}\n",
    "    \"\"\".format(article=article, summary=summary)\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratePromptGood(article, summary):\n",
    "    prompt = \"\"\"\n",
    "    You will be given one summary written for a news article. Your task is to rate the summary based on the following criteria:\n",
    "    Output format: PERCENTAGE, PERCENTAGE, PERCENTAGE, PERCENTAGE, PERCENTAGE\n",
    "\n",
    "    Evaluation Criteria:\n",
    "    1. Read the news article carefully and identify the main topic and key points.\n",
    "    2. Read the summary and compare it to the news article. Check if the summary covers the main topic and key points of the news article, and if it resents them in a clear and logical order.\n",
    "    3. Rate the summary with 5 percentages, where each one represents how likely the summary is going to get a score from 1 to 5. For example, if you think the summary is 80% likely to get a score of 5, 10% likely to get a score of 4, 5% likely to get a score of 3, 3% likely to get a score of 2, and 1% likely to get a score of 1, you should rate the summary as 80, 10, 5, 3, 2.\n",
    "\n",
    "    Here is the article: {article}\n",
    "\n",
    "    Here is the summary: {summary}\n",
    "    \"\"\".format(article=article, summary=summary)\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Replace with your actual OpenAI API key\n",
    "\n",
    "def ask_chatgpt(prompts, outFilePath):\n",
    "    \"\"\"Queries ChatGPT-3.5-turbo with a list of prompts and returns the responses.\n",
    "\n",
    "    Args:\n",
    "        prompts (list): A list of strings representing the prompts.\n",
    "        outFilePath (str): The path to the file where the responses will be written.\n",
    "    \"\"\"\n",
    "    client = OpenAI(\n",
    "        # This is the default and can be omitted\n",
    "        api_key=\"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\"\n",
    "    )\n",
    "\n",
    "    for prompt in prompts:\n",
    "        ans = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                }\n",
    "            ],\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature=0,\n",
    "        )\n",
    "        ans = ans.choices[0].message.content\n",
    "\n",
    "        with open(outFilePath, 'a') as f:\n",
    "            f.write(ans+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def createPrompts(ds, ds_key, sum_para):\n",
    "    articleKey = ds_keys[ds_key][0]\n",
    "    summaryKey = ds_keys[ds_key][1]\n",
    "    # Only select 10% of the articles to rate\n",
    "    random.seed(42)\n",
    "    list_size = len(ds)\n",
    "    num_true = int(list_size * 0.1)\n",
    "    skip = [False] * num_true + [True] * (list_size - num_true)\n",
    "    random.shuffle(skip)\n",
    "\n",
    "    idx = []\n",
    "    prompts = []\n",
    "    for i in range(len(ds)):\n",
    "        if skip[i]:\n",
    "            continue\n",
    "        idx.append(i)\n",
    "        article = ds[i][articleKey]\n",
    "        summary = ds[i][summaryKey]\n",
    "        prompt = ratePromptGood(article, summary)\n",
    "        prompts.append(prompt)\n",
    "        prompt = ratePromptGood(article, sum_para[i])\n",
    "        prompts.append(prompt)\n",
    "\n",
    "    return idx, prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, prompts=createPrompts(cnn_ds, 'cnn_ds', cnn_sum_para, cnn_sum_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3447"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "_ = ic(prompts[300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ratePromptGood(cnn_ds[0]['article'], cnn_sum_para[0])\n",
    "ans = ask_chatgpt(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = prompts[:3]\n",
    "ask_chatgpt(prompts, 'outputTest.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| prompts[2]: ('\n",
      "                '\n",
      "                 '\n",
      "                '\n",
      "                 '    You will be given one summary written for a news article. Your task is '\n",
      "                 'to rate the summary based on the following criteria:\n",
      "                '\n",
      "                 '    Output format: PERCENTAGE, PERCENTAGE, PERCENTAGE, PERCENTAGE, '\n",
      "                 'PERCENTAGE\n",
      "                '\n",
      "                 '\n",
      "                '\n",
      "                 '    Evaluation Criteria:\n",
      "                '\n",
      "                 '    1. Read the news article carefully and identify the main topic and key '\n",
      "                 'points.\n",
      "                '\n",
      "                 '    2. Read the summary and compare it to the news article. Check if the '\n",
      "                 'summary covers the main topic and key points of the news article, and if it '\n",
      "                 'resents them in a clear and logical order.\n",
      "                '\n",
      "                 '    3. Rate the summary with 5 percentages, where each one represents how '\n",
      "                 'likely the summary is going to get a score from 1 to 5. For example, if you '\n",
      "                 'think the summary is 80% likely to get a score of 5, 10% likely to get a '\n",
      "                 'score of 4, 5% likely to get a score of 3, 3% likely to get a score of 2, '\n",
      "                 'and 1% likely to get a score of 1, you should rate the summary as 80, 10, 5, '\n",
      "                 '3, 2.\n",
      "                '\n",
      "                 '\n",
      "                '\n",
      "                 \"    Here is the article: (CNN)If you've been following the news lately, \"\n",
      "                 'there are certain things you doubtless know about Mohammad Javad Zarif. He '\n",
      "                 'is, of course, the Iranian foreign minister. He has been U.S. Secretary of '\n",
      "                 \"State John Kerry's opposite number in securing a breakthrough in nuclear \"\n",
      "                 'discussions that could lead to an end to sanctions against Iran -- if the '\n",
      "                 \"details can be worked out in the coming weeks. And he received a hero's \"\n",
      "                 'welcome as he arrived in Iran on a sunny Friday morning. \"Long live Zarif,\" '\n",
      "                 'crowds chanted as his car rolled slowly down the packed street. You may well '\n",
      "                 'have read that he is \"polished\" and, unusually for one burdened with such '\n",
      "                 'weighty issues, \"jovial.\" An Internet search for \"Mohammad Javad Zarif\" and '\n",
      "                 '\"jovial\" yields thousands of results. He certainly has gone a long way to '\n",
      "                 'bring Iran in from the cold and allow it to rejoin the international '\n",
      "                 'community. But there are some facts about Zarif that are less well-known. '\n",
      "                 'Here are six: . In September 2013, Zarif tweeted \"Happy Rosh Hashanah,\" '\n",
      "                 'referring to the Jewish New Year. That prompted Christine Pelosi, the '\n",
      "                 'daughter of House Minority Leader Nancy Pelosi, to respond with a tweet of '\n",
      "                 'her own: \"Thanks. The New Year would be even sweeter if you would end '\n",
      "                 'Iran\\'s Holocaust denial, sir.\" And, perhaps to her surprise, Pelosi got a '\n",
      "                 'response. \"Iran never denied it,\" Zarif tweeted back. \"The man who was '\n",
      "                 'perceived to be denying it is now gone. Happy New Year.\" The reference was '\n",
      "                 'likely to former Iranian President Mahmoud Ahmadinejad, who had left office '\n",
      "                 'the previous month. Zarif was nominated to be foreign minister by '\n",
      "                 \"Ahmadinejad's successor, Hassan Rouhami. His foreign ministry notes, perhaps \"\n",
      "                 'defensively, that \"due to the political and security conditions of the time, '\n",
      "                 'he decided to continue his education in the United States.\" That is another '\n",
      "                 'way of saying that he was outside the country during the demonstrations '\n",
      "                 'against the Shah of Iran, which began in 1977, and during the Iranian '\n",
      "                 'Revolution, which drove the shah from power in 1979. Zarif left the country '\n",
      "                 'in 1977, received his undergraduate degree from San Francisco State '\n",
      "                 \"University in 1981, his master's in international relations from the \"\n",
      "                 'University of Denver in 1984 and his doctorate from the University of Denver '\n",
      "                 'in 1988. Both of his children were born in the United States. The website of '\n",
      "                 'the Iranian Foreign Ministry, which Zarif runs, cannot even agree with '\n",
      "                 'itself on when he was born. The first sentence of his official biography, '\n",
      "                 'perhaps in a nod to the powers that be in Tehran, says Zarif was \"born to a '\n",
      "                 'religious traditional family in Tehran in 1959.\" Later on the same page, '\n",
      "                 'however, his date of birth is listed as January 8, 1960. And the Iranian '\n",
      "                 'Diplomacy website says he was born in in 1961 . So he is 54, 55 or maybe '\n",
      "                 'even 56. Whichever, he is still considerably younger than his opposite '\n",
      "                 'number, Kerry, who is 71. The feds investigated him over his alleged role in '\n",
      "                 'controlling the Alavi Foundation, a charitable organization. The U.S. '\n",
      "                 'Justice Department said the organization was secretly run on behalf of the '\n",
      "                 'Iranian government to launder money and get around U.S. sanctions. But last '\n",
      "                 'year, a settlement in the case, under which the foundation agreed to give a '\n",
      "                 '36-story building in Manhattan along with other properties to the U.S. '\n",
      "                 \"government, did not mention Zarif's name. Early in the Iranian Revolution, \"\n",
      "                 'Zarif was among the students who took over the Iranian Consulate in San '\n",
      "                 \"Francisco. The aim, says the website Iranian.com -- which cites Zarif's \"\n",
      "                 'memoirs, titled \"Mr. Ambassador\" -- was to expel from the consulate people '\n",
      "                 'who were not sufficiently Islamic. Later, the website says, Zarif went to '\n",
      "                 'make a similar protest at the Iranian mission to the United Nations. In '\n",
      "                 'response, the Iranian ambassador to the United Nations offered him a job. In '\n",
      "                 'fact, he has now spent more time with Kerry than any other foreign minister '\n",
      "                 'in the world. And that amount of quality time will only increase as the two '\n",
      "                 'men, with help from other foreign ministers as well, try to meet a June 30 '\n",
      "                 'deadline for nailing down the details of the agreement they managed to '\n",
      "                 'outline this week in Switzerland.\n",
      "                '\n",
      "                 '\n",
      "                '\n",
      "                 \"    Here is the summary: ['1. Christopher Swist, the father of one of the \"\n",
      "                 'three children who tragically lost their lives in Palm Bay, Florida, in '\n",
      "                 'March, has spoken about his deep affection for the kids and their shared '\n",
      "                 \"love for Little League baseball.\\\n",
      "                2. In honor of the children\\\\'s passion \"\n",
      "                 'for the sport, the Palm Bay City Council has renamed a local little league '\n",
      "                 'field as \"Angels\\\\\\' Field\".\\\n",
      "                3. Swist has also started a non-profit '\n",
      "                 'organization called 3 Angels Ball For All, aiming to provide underprivileged '\n",
      "                 \"children with opportunities to participate in organized sports.']\n",
      "                \"\n",
      "                 '    ')\n"
     ]
    }
   ],
   "source": [
    "_ = ic(prompts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ChatCompletion' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mans\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ChatCompletion' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "ans[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'70, 20, 5, 3, 2'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.chat_completion.ChatCompletion"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
