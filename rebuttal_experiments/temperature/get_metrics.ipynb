{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datasets\n",
    "import matplotlib.transforms as mtransforms\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "from scipy.stats import wasserstein_distance as wass\n",
    "import pickle as pkl\n",
    "from evaluate import load\n",
    "from datasets import load_dataset, DatasetDict, load_from_disk\n",
    "import os\n",
    "from time import sleep\n",
    "from tqdm.auto import tqdm\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bertscore(data):\n",
    "    \n",
    "    highlights = []\n",
    "    model_s = []\n",
    "\n",
    "\n",
    "    # for j in data['highlights']:\n",
    "    #     highlights.append(' '.join(j))\n",
    "\n",
    "    # for k in data['model_summaries']:\n",
    "    #     model_s.append(' '.join(k))\n",
    "    \n",
    "    bertscore = load(\"bertscore\")\n",
    "    \n",
    "    results = bertscore.compute(predictions=data['model_summaries'], references=data['highlights'], lang=\"en\", device='cuda:1')\n",
    "    mean_precision=sum(results['precision'])/len(results['precision'])\n",
    "    mean_recall=sum(results['recall'])/len(results['recall'])\n",
    "    mean_f1=sum(results['f1'])/len(results['f1'])\n",
    "    \n",
    "    return mean_precision,mean_recall,mean_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rouge1(data):\n",
    "\n",
    "    highlights = []\n",
    "    model_s = []\n",
    "\n",
    "\n",
    "    # for j in data['highlights']:\n",
    "    #     highlights.append(' '.join(j))\n",
    "\n",
    "    # for k in data['model_summaries']:\n",
    "    #     model_s.append(' '.join(k))\n",
    "\n",
    "\n",
    "    rouge = evaluate.load('rouge')\n",
    "\n",
    "    print(\"==> Comparing generated summaries with gold summaries\")\n",
    "    results = rouge.compute(predictions=data['model_summaries'], references=data['highlights'])\n",
    "    \n",
    "    return results['rouge1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rouge2(data):\n",
    "\n",
    "    highlights = []\n",
    "    model_s = []\n",
    "\n",
    "\n",
    "    # for j in data['highlights']:\n",
    "    #     highlights.append(' '.join(j))\n",
    "\n",
    "    # for k in data['model_summaries']:\n",
    "    #     model_s.append(' '.join(k))\n",
    "\n",
    "\n",
    "    rouge = evaluate.load('rouge')\n",
    "\n",
    "    print(\"==> Comparing generated summaries with gold summaries\")\n",
    "    results = rouge.compute(predictions=data['model_summaries'], references=data['highlights'])\n",
    "    \n",
    "    return results['rouge2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rougeL(data):\n",
    "\n",
    "    highlights = []\n",
    "    model_s = []\n",
    "\n",
    "\n",
    "    # for j in data['highlights']:\n",
    "    #     highlights.append(' '.join(j))\n",
    "\n",
    "    # for k in data['model_summaries']:\n",
    "    #     model_s.append(' '.join(k))\n",
    "\n",
    "\n",
    "    rouge = evaluate.load('rouge')\n",
    "\n",
    "    print(\"==> Comparing generated summaries with gold summaries\")\n",
    "    results = rouge.compute(predictions=data['model_summaries'], references=data['highlights'])\n",
    "    \n",
    "    return results['rougeL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results-xsum.pkl', 'rb') as f:\n",
    "    xsum_original=pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results-paraphrased-xsum.pkl', 'rb') as f:\n",
    "    xsum_paraphrased=pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.pkl', 'rb') as f:\n",
    "    cnn_original=pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results-paraphrased-cnn.pkl', 'rb') as f:\n",
    "    cnn_paraphrased=pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cnn_paraphrased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsum_original_first=[]\n",
    "for items in cnn_original:\n",
    "    xsum_original_first.append(items[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsum_paraphrased_first=[]\n",
    "for items in cnn_paraphrased:\n",
    "    xsum_paraphrased_first.append(items[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1. The Palestinian Authority has officially become a member of the International Criminal Court, granting the court jurisdiction over alleged crimes committed in Palestinian territories.\\n\\n2. This move has been met with opposition from Israel and the United States, who both opposed the Palestinians' membership in the ICC.\\n\\n3. The ICC's preliminary examination will review evidence and determine whether to investigate war crimes committed by both Israelis and Palestinians since June 2014.\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsum_original_first[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. The Palestinian Authority has become a member of the International Criminal Court, giving the court jurisdiction to investigate alleged crimes in the Palestinian territories.'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsum_paraphrased_first[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkls=os.listdir('../../paraphrased_articles/cnn')\n",
    "pkls=natsorted(pkls)\n",
    "pkls_list=[]\n",
    "count=0\n",
    "bad_index=[]\n",
    "for k,pikl in enumerate(pkls):\n",
    "    with open('../../paraphrased_articles/cnn/{}'.format(pikl),'rb') as f:\n",
    "        file=pkl.load(f)\n",
    "    if not file and k<100:\n",
    "        bad_index.append(k)\n",
    "        count+=1\n",
    "        file.append(' ') #no paraphrasing possible\n",
    "    pkls_list.extend(file)\n",
    "\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_llama_cnn.select(i for i in range(len(data_llama_cnn)) \n",
    "#                  if i not in set(bad_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article', 'highlights', 'id', 'model_summaries'],\n",
       "    num_rows: 96\n",
       "})"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"cnn_dailymail\", '3.0.0')\n",
    "article_key = 'document'\n",
    "summary_key = 'highlights'\n",
    "data_original=dataset['test']\n",
    "data_original=data_original.select(range(100))\n",
    "data_original = data_original.add_column('model_summaries', xsum_original_first)\n",
    "#data[article_key]=pkls_list\n",
    "data_original.select(i for i in range(len(data_original)) \n",
    "                 if i not in set(bad_index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article', 'highlights', 'id', 'model_summaries'],\n",
       "    num_rows: 96\n",
       "})"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"cnn_dailymail\", '3.0.0')\n",
    "article_key = 'document'\n",
    "summary_key = 'highlights'\n",
    "data_paraphrased=dataset['test']\n",
    "data_paraphrased=data_paraphrased.select(range(100))\n",
    "data_paraphrased = data_paraphrased.add_column('model_summaries', xsum_paraphrased_first)\n",
    "#data[article_key]=pkls_list\n",
    "data_paraphrased.select(i for i in range(len(data_paraphrased)) \n",
    "                 if i not in set(bad_index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8582734239101409, 0.8844329518079758, 0.871051213145256)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bertscore(data_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Comparing generated summaries with gold summaries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2850808951574686"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rouge1(data_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Comparing generated summaries with gold summaries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.107321159671523"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rouge2(data_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Comparing generated summaries with gold summaries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20249389712647695"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rougeL(data_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
