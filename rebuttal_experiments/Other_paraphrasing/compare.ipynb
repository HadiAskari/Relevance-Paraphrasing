{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haskari/miniconda3/envs/acl/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to /home/haskari/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-29 23:11:27,345] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "import fire\n",
    "\n",
    "from llama import Llama, Dialog\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from time import sleep\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pickle as pkl\n",
    "import os\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']=\"1,2\"\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import torch\n",
    "from datasets import load_dataset, DatasetDict, load_from_disk\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from nltk import sent_tokenize\n",
    "import math, re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "from transformers import Trainer, TrainingArguments, pipeline\n",
    "import argparse\n",
    "import evaluate\n",
    "# from styleformer import Styleformer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import copy\n",
    "import multiprocessing\n",
    "import pickle as pkl\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from time import sleep\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rouge(original_sentences_final,paraphrased_sentences_final):\n",
    "    highlights = []\n",
    "    model_s = []\n",
    "    \n",
    "    for j in original_sentences_final:\n",
    "        highlights.append(' '.join(j))\n",
    "\n",
    "    for k in paraphrased_sentences_final:\n",
    "        model_s.append(' '.join(k))\n",
    "\n",
    "\n",
    "    rouge = evaluate.load('rouge')\n",
    "\n",
    "    print(\"==> Comparing generated summaries with gold summaries\")\n",
    "    results = rouge.compute(predictions=model_s, references=highlights)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bertscore(original_sentences_final,paraphrased_sentences_final):\n",
    "    \n",
    "    highlights = []\n",
    "    model_s = []\n",
    "\n",
    "\n",
    "    for j in original_sentences_final:\n",
    "        highlights.append(' '.join(j))\n",
    "\n",
    "    for k in paraphrased_sentences_final:\n",
    "        model_s.append(' '.join(k))\n",
    "    \n",
    "    bertscore = load(\"bertscore\")\n",
    "    \n",
    "    results = bertscore.compute(predictions=model_s, references=highlights, lang=\"en\", device='cuda:1')\n",
    "    mean_precision=sum(results['precision'])/len(results['precision'])\n",
    "    mean_recall=sum(results['recall'])/len(results['recall'])\n",
    "    mean_f1=sum(results['f1'])/len(results['f1'])\n",
    "    \n",
    "    return mean_precision,mean_recall,mean_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_data/cnn/deep1_cnn_train_42.pkl', 'rb') as f:\n",
    "    deep1=pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_data/cnn/deep2_cnn_train_42.pkl', 'rb') as f:\n",
    "    deep2=pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_data/cnn/llama.pkl', 'rb') as f:\n",
    "    llama=pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_data/cnn/original.pkl', 'rb') as f:\n",
    "    original=pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The Palestinians signed the ICC\\'s founding Rome Statute in January, when they also accepted its jurisdiction over alleged crimes committed \"in the occupied Palestinian territory, including East Jerusalem, since June 13, 2014.\"',\n",
       "  'Later that month, the ICC opened a preliminary examination into the situation in Palestinian territories, paving the way for possible war crimes investigations against Israelis.',\n",
       "  \"Israel and the United States, neither of which is an ICC member, opposed the Palestinians' efforts to join the body.\",\n",
       "  'The inquiry will include alleged war crimes committed since June.'],\n",
       " ['A stray pooch in Washington State has used up at least three of her own after being hit by a car, apparently whacked on the head with a hammer in a misguided mercy killing and then buried in a field -- only to survive.',\n",
       "  'Four days after her apparent death, the dog managed to stagger to a nearby farm, dirt-covered and emaciated, where she was found by a worker who took her to a vet for help.',\n",
       "  '\"She\\'s a true miracle dog and she deserves a good life.\"',\n",
       "  \"A cat in Tampa, Florida, found seemingly dead after he was hit by a car in January, showed up alive in a neighbor's yard five days after he was buried by his owner.\"],\n",
       " ['He is, of course, the Iranian foreign minister.',\n",
       "  'An Internet search for \"Mohammad Javad Zarif\" and \"jovial\" yields thousands of results.',\n",
       "  \"Zarif left the country in 1977, received his undergraduate degree from San Francisco State University in 1981, his master's in international relations from the University of Denver in 1984 and his doctorate from the University of Denver in 1988.\",\n",
       "  'Early in the Iranian Revolution, Zarif was among the students who took over the Iranian Consulate in San Francisco.',\n",
       "  'In fact, he has now spent more time with Kerry than any other foreign minister in the world.'],\n",
       " ['(CNN)Five Americans who were monitored for three weeks at an Omaha, Nebraska, hospital after being exposed to Ebola in West Africa have been released, a Nebraska Medicine spokesman said in an email Wednesday.',\n",
       "  'They were exposed to Ebola in Sierra Leone in March, but none developed the deadly virus.',\n",
       "  'They all had contact with a colleague who was diagnosed with the disease and is being treated at the National Institutes of Health in Bethesda, Maryland.',\n",
       "  'As of Monday, that health care worker is in fair condition.',\n",
       "  'Ebola is spread by direct contact with the bodily fluids of an infected person.'],\n",
       " ['(CNN)A Duke student has admitted to hanging a noose made of rope from a tree near a student union, university officials said Thursday.',\n",
       "  'In a news release, it said the student was no longer on campus and will face student conduct review.',\n",
       "  'The student was identified during an investigation by campus police and the office of student affairs and admitted to placing the noose on the tree early Wednesday, the university said.',\n",
       "  'At a forum held on the steps of Duke Chapel, close to where the noose was discovered at 2 a.m., hundreds of people gathered.',\n",
       "  'This is no Duke we want.'],\n",
       " [\"She's a high school freshman with Down syndrome.\",\n",
       "  \"Trey -- a star on Eastern High School's basketball team in Louisville, Kentucky, who's headed to play college ball next year at Ball State -- was originally going to take his girlfriend to Eastern's prom.\",\n",
       "  \"Trey made the prom-posal (yes, that's what they are calling invites to prom these days) in the gym during Ellie's P.E.\",\n",
       "  \"Trina Helson, a teacher at Eastern, alerted the school's newspaper staff to the prom-posal and posted photos of Trey and Ellie on Twitter that have gone viral.\"],\n",
       " ['(CNN)Governments around the world are using the threat of terrorism -- real or perceived -- to advance executions, Amnesty International alleges in its annual report on the death penalty.',\n",
       "  '\"It is shameful that so many states around the world are essentially playing with people\\'s lives -- putting people to death for \\'terrorism\\' or to quell internal instability on the ill-conceived premise of deterrence.\"',\n",
       "  'On one hand, the number of executions worldwide has gone down by almost 22% on the previous year.',\n",
       "  'While the report notes some encouraging signs, it also highlights a marked increase in the number of people sentenced to death in 2014.',\n",
       "  'The United States has the dubious distinction of being the only country in the Americas to conduct executions, but the number of convicts put to death here fell slightly, from 39 in 2013 to 35 in 2014.'],\n",
       " ['(CNN)Andrew Getty, one of the heirs to billions of oil money, appears to have died of natural causes, a Los Angeles Police Department spokesman said.',\n",
       "  \"The coroner's preliminary assessment is there was no foul play involved in the death of Getty, grandson of oil tycoon J. Paul Getty, said Detective Meghan Aguilar.\",\n",
       "  'There is no criminal investigation underway, he said.',\n",
       "  'Gordon Getty is one of three living sons of J. Paul Getty, the oil baron who was thought to be the richest man in the world at the time of his death in 1976.',\n",
       "  'Court records show Andrew Getty had recently filed to get a restraining order against an ex-girlfriend.',\n",
       "  'In his request, Getty said he had been diagnosed with a serious medical condition in 2013.'],\n",
       " ['Just a few days ago, Maysak gained super typhoon status thanks to its sustained 150 mph winds.',\n",
       "  'It has since lost a lot of steam as it has spun west in the Pacific Ocean.',\n",
       "  'It boasts steady winds of more than 70 mph (115 kph) and gusts up to 90 mph as of 5 p.m. (5 a.m.',\n",
       "  \"It's expected to make landfall Sunday morning on the southeastern coast of Isabela province and be out of the Philippines by Monday.\"],\n",
       " ['on the April 1 edition of \"The Price Is Right\" encountered not host Drew Carey but another familiar face in charge of the proceedings.',\n",
       "  'Instead, there was Bob Barker, who hosted the TV game show for 35 years before stepping down in 2007.',\n",
       "  'Looking spry at 91, Barker handled the first price-guessing game of the show, the classic \"Lucky Seven,\" before turning hosting duties over to Carey, who finished up.']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Later that month, the ICC opened a preliminary examination into the situation in Palestinian territories, paving the way for possible war crimes investigations against Israelis.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Palestinian authorities signed the ICC's founding Rome Statute in January, thereby acknowledging the court's authority to investigate and prosecute alleged crimes committed in the occupied Palestinian territories, including East Jerusalem, dating back to June 13, 2014.\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0.924246609210968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "0.9238621592521667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "0.9233897924423218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n",
      "0.9012101292610168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "mini=0.99\n",
    "for i in range(len(original)):\n",
    "    for j in range(len(original[i])):\n",
    "        try:\n",
    "            res=get_bertscore([original[i][j]],[llama[i][j]])\n",
    "        except:\n",
    "            pass\n",
    "        if res[2]<mini:\n",
    "            print(i,j)\n",
    "            mini=res[2]\n",
    "            print(mini)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['(CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories.',\n",
       "  \"The Palestinian authorities signed the ICC's founding Rome Statute in January, thereby acknowledging the court's authority to investigate and prosecute alleged crimes committed in the occupied Palestinian territories, including East Jerusalem, dating back to June 13, 2014.\",\n",
       "  \"Neither Israel nor the United States, both of which are not members of the International Criminal Court (ICC), objected to the Palestinians' attempts to join the ICC.\",\n",
       "  'The International Criminal Court was set up in 2002 to prosecute genocide, crimes against humanity and war crimes.'],\n",
       " ['A wandering dog in Washington State has miraculously survived being struck by a car, despite suffering head injuries from a hammer attack and being buried in a field.',\n",
       "  \"That's according to Washington State University, where the dog -- a friendly white-and-black bully breed mix now named Theia -- has been receiving care at the Veterinary Teaching Hospital.\",\n",
       "  'The dog, who had been presumed dead for four days, miraculously made her way to a nearby farm, badly injured and severely underweight, where she was discovered by a worker who rushed her to a veterinarian for medical attention.',\n",
       "  '\"She is a remarkable canine with a remarkable story, and she deserves to live a happy and fulfilling life.\"'],\n",
       " ['He serves as the foreign minister of Iran, naturally.',\n",
       "  'A search online for \"Mohammad Javad Zarif\" and \"humorous\" returns thousands of results.',\n",
       "  \"Zarif departed the country in 1977, later earning his undergraduate degree from San Francisco State University in 1981, his master's in international relations from the University of Denver in 1984, and his doctorate from the same institution in 1988.\",\n",
       "  'At the outset of the Iranian Revolution, Zarif was one of the student protesters who occupied the Iranian Consulate in San Francisco.',\n",
       "  'He has spent more time with Kerry than with any other foreign minister in the world.'],\n",
       " ['According to a spokesman for Nebraska Medicine, five American individuals who were being monitored at an Omaha hospital after being exposed to Ebola in West Africa have been released.',\n",
       "  'They encountered Ebola in Sierra Leone in March, yet none of them contracted the fatal infection.',\n",
       "  'All of them had come into contact with a colleague who was diagnosed with the disease and is currently undergoing treatment at the National Institutes of Health in Bethesda, Maryland.',\n",
       "  'As of Monday, the healthcare professional is recovering well and is in fair health.',\n",
       "  'The Centers for Disease Control and Prevention in Atlanta has said the last of 17 patients who were being monitored are expected to be released by Thursday.'],\n",
       " ['According to university officials, a student at Duke University has confessed to hanging a rope noose from a tree near a student union.',\n",
       "  'According to a recent news release, the student is no longer attending the campus and will be subject to a review of their conduct.',\n",
       "  'The university reported that the student was discovered by campus police and the office of student affairs to have placed a noose on a tree on Wednesday morning, following an investigation.',\n",
       "  'On the grounds of Duke Chapel, near the site where a noose was found at 2 a.m., a large crowd of people convened for a forum.'],\n",
       " ['She is a freshman in high school who has Down syndrome.',\n",
       "  \"Trey, a standout basketball player at Eastern High School in Louisville, Kentucky, who will be attending Ball State University next year, had initially planned to take his girlfriend to the school's prom.\",\n",
       "  'Trey asked Ellie to prom in the gym during her physical education class.',\n",
       "  \"Trina Helson, a teacher at Eastern High School, brought the prom-posal to the attention of the school's newspaper staff and shared photos of Trey and Ellie on Twitter, which have since gone viral.\"],\n",
       " [\"According to Amnesty International's annual report on the death penalty, governments worldwide are exploiting the specter of terrorism, both real and perceived, to justify the use of capital punishment.\",\n",
       "  'In contrast to previous years, the global number of executions has decreased by nearly 22% in the past year.',\n",
       "  '(There are) signals of a world that is nearing abolition.\"',\n",
       "  'The report observes some positive developments, but it also reveals a significant rise in the number of death sentences handed down in 2014.',\n",
       "  'The report also highlights the imperfections in the judiciary processes that lead to many sentenced to death.'],\n",
       " ['According to the Los Angeles Police Department, Andrew Getty, an heir to a vast fortune in oil wealth, passed away due to natural causes.',\n",
       "  'He emphasized that there is no active criminal probe currently in progress.',\n",
       "  'Where the Getty family fortune came from .',\n",
       "  'According to court records, Andrew Getty had recently sought legal protection against his former partner through a restraining order.',\n",
       "  'Getty mentioned in his request that he was diagnosed with a severe medical condition back in 2013.',\n",
       "  \"CNN's Doug Criss, Janet DiGiacomo, Mark Mooney, Mike Love, Julie In and Cheri Mossburg contributed to this report.\"],\n",
       " ['Maysak recently reached super typhoon status due to its consistent winds of 150 miles per hour.',\n",
       "  'It has since lost momentum as it has veered westward in the Pacific Ocean.',\n",
       "  'Strong and consistent winds of over 70 mph (115 kph) and gusts reaching up to 90 mph have been recorded as of 5 p.m. (5 a.m.).',\n",
       "  'Gabriel Llave, a disaster official, told PNA that tourists who arrive Saturday in and around the coastal town of Aurora \"will not be accepted by the owners of hotels, resorts, inns and the like ... and will be advised to return to their respective places.\"'],\n",
       " ['On April 1st, viewers of \"The Price Is Right\" were surprised to see not host Drew Carey, but another familiar face leading the show.',\n",
       "  'Bob Barker hosted the popular TV game show for an impressive 35 years before deciding to step down in 2007.',\n",
       "  'Barker, who appeared youthful at 91, kicked off the first price-guessing game of the show, \"Lucky Seven,\" before passing the baton to Carey to conclude the segment.']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Comparing generated summaries with gold summaries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.6046319897000807,\n",
       " 'rouge2': 0.34075127133367616,\n",
       " 'rougeL': 0.4911236178123376,\n",
       " 'rougeLsum': 0.48671103507437535}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=get_rouge(original,llama)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9207142353057861, 0.9227013528347016, 0.9216248691082001)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=get_bertscore(original,llama)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Comparing generated summaries with gold summaries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.8016979114269704,\n",
       " 'rouge2': 0.6503130686789088,\n",
       " 'rougeL': 0.7230080413080415,\n",
       " 'rougeLsum': 0.721497476332927}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=get_rouge(original,deep1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9500763654708863, 0.9358047723770142, 0.9428768575191497)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=get_bertscore(original,deep1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Comparing generated summaries with gold summaries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.7219889549496454,\n",
       " 'rouge2': 0.47466018448382463,\n",
       " 'rougeL': 0.5501737804229176,\n",
       " 'rougeLsum': 0.5487110926931477}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=get_rouge(original,deep2)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.938933914899826, 0.9396045744419098, 0.9392397344112396)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=get_bertscore(original,deep2)\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
